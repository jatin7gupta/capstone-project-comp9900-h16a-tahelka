{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /anaconda3/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /anaconda3/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: joblib in /anaconda3/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: click in /anaconda3/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /anaconda3/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#create movieid: cast list dictionary \n",
    "fc = pd.read_csv('FilmCast.csv', header = 0) #title \n",
    "fd = pd.read_csv('FilmDirector.csv', header = 0) #title \n",
    "person = pd.read_csv('Person.csv', header = 0) #title \n",
    "fc = pd.merge(person,fc,on='personID')\n",
    "fd = pd.merge(person,fd,on='personID')\n",
    "person = fc.append(fd)\n",
    "movie_person = dict()\n",
    "for i in range(len(person)):\n",
    "    if person.iloc[i,2] in movie_person:\n",
    "        movie_person[person.iloc[i,2]].append(person.iloc[i,1].replace(\" \", \"\"))\n",
    "    else:\n",
    "        movie_person[person.iloc[i,2]] = [person.iloc[i,1].replace(\" \", \"\")]\n",
    "\n",
    "#create movieid: genre list dictionary \n",
    "genre = pd.read_csv('GenreOfFilm.csv', header = 0)\n",
    "genlist = pd.read_csv('Genres.csv', header = 0)\n",
    "gen = pd.merge(genlist,genre,on='genreID')\n",
    "movie_genre = dict()\n",
    "for i in range(len(gen)):\n",
    "    if gen.iloc[i,2] in movie_genre:\n",
    "        movie_genre[gen.iloc[i,2]].append(gen.iloc[i,0])\n",
    "    else:\n",
    "        movie_genre[gen.iloc[i,2]] = [gen.iloc[i,0]]\n",
    "        \n",
    "        \n",
    "movies = pd.read_csv('Movie.csv', header = 0) #title \n",
    "for i in range(len(movies)):\n",
    "    movies.iloc[i,4] = [' '.join(word for word in movie_genre[movies.iloc[i,0]])]       #genre list for that movieid\n",
    "    movies.iloc[i,5] = [' '.join(word for word in movie_person[movies.iloc[i,0]])]      #cast list for that movieid\n",
    "    \n",
    "# movies = movies.rename(columns = {'total_ratings':'genre', 'rating_count':'cast'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(movies)):\n",
    "    try:\n",
    "        desc = movies.iloc[i,3]\n",
    "        tokens = word_tokenize(desc)\n",
    "        words = [word for word in tokens if word.isalpha()]              #remove non letters\n",
    "        words = [word for word in words if not word in stop_words]       #remove stopwords\n",
    "        words = [word.lower() for word in words]                         #convert to lower case\n",
    "        movies.iloc[i,3] = ' '.join(word for word in words)              #join as a single string\n",
    "    except:\n",
    "        movies.iloc[i,3] = ''                                            #if nan replace with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(movies)):\n",
    "    movies.iloc[i,1] = [str(movies.iloc[i,1]) + ' ' + str(movies.iloc[i,2]) + ' ' + str(movies.iloc[i,3]) + ' ' + str(movies.iloc[i,4])]\n",
    "movies.drop(columns = ['year','description','total_ratings','rating_count'], inplace = True)\n",
    "movies = movies.rename(columns = {'title':'bag_of_words'})\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "count = CountVectorizer()\n",
    "matrix = count.fit_transform(movies['bag_of_words'])   #generating the count matrix\n",
    "\n",
    "cosine_sim = cosine_similarity(matrix, matrix)         #cosine similarity matrix\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data as a dataframe \n",
    "sim = pd.DataFrame(data=cosine_sim[0:,0:],        # values\n",
    "...              index=movies.movieID,            # set index\n",
    "...              columns=movies.movieID)          # column names\n",
    "sim['movieID'] = sim.index                        #add a column for movieID\n",
    "# sim.to_csv('sim.csv',index=False)               #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query dataframe                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim = pd.read_csv('sim.csv', header = 0)   \n",
    "inputid = 113041.0                                          #should be the value from the user's input\n",
    "row_index = sim.index[sim['movieID'] == inputid][0]\n",
    "arr = sim.iloc[row_index]\n",
    "top_1000 = list(arr.sort_values(ascending = False)[2:1002]) #top 1000 similar movieids as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
